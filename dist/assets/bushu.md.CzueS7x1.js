import{_ as a,c as t,o as e,a5 as r}from"./chunks/framework.-Zveb6AF.js";const d=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"bushu.md","filePath":"bushu.md"}'),o={name:"bushu.md"},n=r('<p><a name="GXrzo"></a></p><h2 id="项目背景" tabindex="-1">项目背景 <a class="header-anchor" href="#项目背景" aria-label="Permalink to &quot;项目背景&quot;">​</a></h2><blockquote><p>大家都调侃说2023年是AI元年，不得不说AI在我们生活中逐渐扮演着越来越重要的角色，如何有效的把AI模型结合当前生产生活实际显得尤为重要，基于此并结合专业知识，我们想打造一款工业消防类型的AI知识库模型，在现有的AI模型基础之上，使用微调技术，收集所需数据集进行微调。</p></blockquote><ul><li>想法来源：</li></ul><p><a href="https://mp.weixin.qq.com/s/_sJsjdp0sIcD0Vh5oqMMZA" target="_blank" rel="noreferrer">校企合作！基于文心大模型共建水科学研究助手WaterScholar</a></p><ul><li>具体思考</li></ul><blockquote><p>市面上不缺乏各式各样的对话模型，但是都是基于底层AI大模型的调用，不能做到有针对性的回答某个非常细化的问题，所以说一个细化的AI知识库就显得尤为重要了，但是我们不可能从零开始去训练一个模型，不论是从技术，成本等等方面。随着 ChatGPT 的爆火，很多机构都开源了自己的大模型，比如ChatGLM-6B/ChatGLM-10B/ChatGLM-130B，HuggingFace 的 BLOOM-176B，LLAMA2， 这些大公司或者研究机构，都是有足够资源的来开发大模型，但是对于一般的小公司或者个人来说，要想开发自己的大模型几乎不可能，要知道像 ChatGPT 这样的大模型，一次训练的成本就在上千亿美元。 那么针对于小公司或者个人，我们怎么能够利用这些开源的大模型，在自己的数据上继续训练，从而应用于自己的业务场景？有没有低成本的方法微调大模型？ 答案是有的。目前主流的方法包括2019年 Houlsby N 等人提出的 Adapter Tuning，2021年微软提出的 LORA，斯坦福提出的 Prefix-Tuning，谷歌提出的 Prompt Tuning，2022年清华提出的 P-tuning v2。 <br>我选择的是<strong>ChatGLM3-6B模型+LORA/</strong><a href="https://github.com/hiyouga/LLaMA-Factory" target="_blank" rel="noreferrer"><strong>LLaMA-Factory</strong></a><strong>+</strong><a href="https://github.com/chatchat-space/Langchain-Chatchat" target="_blank" rel="noreferrer"><strong>LangChain-Chatchat</strong></a><strong>，使用ChatGLM3-6B作为预训练模型，使用LORA和</strong><a href="https://github.com/hiyouga/LLaMA-Factory" target="_blank" rel="noreferrer"><strong>LLaMA-Factory</strong></a><strong>微调框架，使用</strong><a href="https://github.com/chatchat-space/Langchain-Chatchat" target="_blank" rel="noreferrer"><strong>LangChain-Chatchat</strong></a><strong>作为应用框架，整体的思路以上这些，下面是实现过程的一些记录，完整的内容可以查看我们推出的文档</strong></p></blockquote><p><img src="https://cdn.nlark.com/yuque/0/2024/jpeg/40770342/1713534844417-277cc4bb-c816-465c-bf6b-6a3b8aa7cd38.jpeg" alt=""><a name="kxZEa"></a></p><h3 id="chatglm3-6b介绍" tabindex="-1">ChatGLM3-6B介绍 <a class="header-anchor" href="#chatglm3-6b介绍" aria-label="Permalink to &quot;ChatGLM3-6B介绍&quot;">​</a></h3><p><strong>ChatGLM3</strong> 是智谱AI和清华大学 KEG 实验室联合发布的对话预训练模型。ChatGLM3-6B 是 ChatGLM3 系列中的开源模型，在保留了前两代模型对话流畅、部署门槛低等众多优秀特性的基础上，ChatGLM3-6B 引入了如下特性：</p><ol><li><strong>更强大的基础模型：</strong> ChatGLM3-6B 的基础模型 ChatGLM3-6B-Base 采用了更多样的训练数据、更充分的训练步数和更合理的训练策略。在语义、数学、推理、代码、知识等不同角度的数据集上测评显示，* <em>ChatGLM3-6B-Base 具有在 10B 以下的基础模型中最强的性能</em>*。</li><li><strong>更完整的功能支持：</strong> ChatGLM3-6B 采用了全新设计的 <a href="https://github.com/THUDM/ChatGLM3/blob/main/PROMPT.md" target="_blank" rel="noreferrer">Prompt 格式</a> ，除正常的多轮对话外。同时原生支持<a href="https://github.com/THUDM/ChatGLM3/blob/main/tools_using_demo/README.md" target="_blank" rel="noreferrer">工具调用</a>（Function Call）、代码执行（Code Interpreter）和 Agent 任务等复杂场景。</li><li><strong>更全面的开源序列：</strong> 除了对话模型 <a href="https://huggingface.co/THUDM/chatglm3-6b" target="_blank" rel="noreferrer">ChatGLM3-6B</a> 外，还开源了基础模型 <a href="https://huggingface.co/THUDM/chatglm3-6b-base" target="_blank" rel="noreferrer">ChatGLM3-6B-Base</a> 、长文本对话模型 <a href="https://huggingface.co/THUDM/chatglm3-6b-32k" target="_blank" rel="noreferrer">ChatGLM3-6B-32K</a> 和进一步强化了对于长文本理解能力的 <a href="https://huggingface.co/THUDM/chatglm3-6b-128k" target="_blank" rel="noreferrer">ChatGLM3-6B-128K</a>。以上所有权重对学术研究<strong>完全开放</strong> ，在填写 <a href="https://open.bigmodel.cn/mla/form" target="_blank" rel="noreferrer">问卷</a> 进行登记后<strong>亦允许免费商业使用</strong>。</li></ol><ul><li>工业上需要</li><li>痛点2...</li><li>痛点3...</li><li><img src="https://cdn.nlark.com/yuque/0/2024/png/40770342/1713532887077-7c5b7b45-fee4-45c4-b03e-8c760b9045eb.png#averageHue=%231d1f26&amp;clientId=ud8a2223e-5bb6-4&amp;from=paste&amp;height=1019&amp;id=u1db34abb&amp;originHeight=1274&amp;originWidth=2374&amp;originalType=binary&amp;ratio=1.25&amp;rotation=0&amp;showTitle=false&amp;size=558212&amp;status=done&amp;style=none&amp;taskId=ua80c1d4e-8f6b-46eb-8884-1e54b9ca1f6&amp;title=&amp;width=1899.2" alt="微信图片_20240419212033.png"><a name="sKxNP"></a></li></ul><h2 id="项目目标" tabindex="-1">项目目标 <a class="header-anchor" href="#项目目标" aria-label="Permalink to &quot;项目目标&quot;">​</a></h2><blockquote><ol><li>企业可做到模型可自主部署</li><li>模型知识库做到较大范围的</li><li>可以达到的（Attainable）</li><li>要与其他目标具有一定的相关性（Relevant）</li><li>有明确的截止期限（Time-bound）</li></ol></blockquote><p><a name="pWj60"></a></p><h2 id="" tabindex="-1"><a class="header-anchor" href="#" aria-label="Permalink to &quot;&quot;">​</a></h2><p><a name="qEz8o"></a></p><h2 id="关键事项" tabindex="-1">关键事项 <a class="header-anchor" href="#关键事项" aria-label="Permalink to &quot;关键事项&quot;">​</a></h2><blockquote><p>为达成上述目标，需要完成哪些关键事项。</p></blockquote><ul><li>关键事项1...</li><li>关键事项2...</li><li>关键事项3... <a name="x4NTt"></a></li></ul><h2 id="里程碑" tabindex="-1">里程碑 <a class="header-anchor" href="#里程碑" aria-label="Permalink to &quot;里程碑&quot;">​</a></h2><blockquote><p>整个项目中，关键节点的里程碑计划。</p></blockquote><p><img src="https://cdn.nlark.com/yuque/0/2022/jpeg/956523/1657187439577-9e5f23b1-b37f-41ff-989b-646e87f85d6d.jpeg" alt=""><a name="mPvHi"></a></p><h2 id="人员安排" tabindex="-1">人员安排 <a class="header-anchor" href="#人员安排" aria-label="Permalink to &quot;人员安排&quot;">​</a></h2><blockquote><p>输入项目的所有干系人，包括内部和外部干系人。</p></blockquote><table><thead><tr><th><strong>人员</strong></th><th><strong>岗位</strong></th></tr></thead><tbody><tr><td>@提及</td><td>项目经理</td></tr><tr><td>@提及</td><td>技术负责人</td></tr><tr><td>@提及</td><td>产品负责人</td></tr></tbody></table><p><a name="w645V"></a></p><h2 id="风险提示" tabindex="-1">风险提示 <a class="header-anchor" href="#风险提示" aria-label="Permalink to &quot;风险提示&quot;">​</a></h2><blockquote><p>对公司战略、项目结题、法务风险问题进行提示，并说明应对措施。</p></blockquote>',29),l=[n];function h(i,s,c,g,b,p){return e(),t("div",null,l)}const m=a(o,[["render",h]]);export{d as __pageData,m as default};
